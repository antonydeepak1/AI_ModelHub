# -*- coding: utf-8 -*-
"""ATS RESUME TRACKER.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SvQqClM2xb1LQPuTUHI4wwXt40TGy8_8
"""

!pip install gradio fitz PyMuPDF layoutparser transformers torch torchvision \
sentence-transformers keybert nltk pillow

!pip install pytesseract
!pip install PyMuPDF==1.22.5
!pip install -U bitsandbytes accelerate transformers
!pip install transformers torch gradio sentence-transformers pdfplumber pytesseract
!pip install -U bitsandbytes
!pip install fastapi uvicorn pyngrok python-multipart pdfplumber pytesseract pillow sentence-transformers

# STEP 1: Install dependencies
!pip install -q sentence-transformers pdfplumber pytesseract pillow pyngrok fastapi uvicorn nest_asyncio

# STEP 2: Imports
import torch
import pdfplumber
import pytesseract
from PIL import Image
import re
import tempfile
import time
import threading
from fastapi import FastAPI, UploadFile, Form
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from sentence_transformers import SentenceTransformer, util
from pyngrok import ngrok
import nest_asyncio
import uvicorn  # ‚úÖ Added this line
from google.colab.output import eval_js

# STEP 3: Asyncio support for Colab
nest_asyncio.apply()

# STEP 4: Load embedding model
print("üîß Loading BGE model...")
embedder = SentenceTransformer("BAAI/bge-small-en", device="cuda" if torch.cuda.is_available() else "cpu")
print("‚úÖ Model loaded!")

# STEP 5: FastAPI app
app = FastAPI(title="Resume Analyzer", description="ATS Match + Cover Letter Generator", version="1.0")

# Utility functions
def clean_text(text):
    return ' '.join(text.strip().split())

def extract_text_from_pdf(path):
    with pdfplumber.open(path) as pdf:
        return clean_text("\n".join(page.extract_text() or "" for page in pdf.pages))

def extract_text_from_image(path):
    image = Image.open(path)
    return clean_text(pytesseract.image_to_string(image))

def extract_name(text):
    for line in text.split("\n")[:5]:
        if re.match(r"^[A-Z][a-z]+ [A-Z][a-z]+", line.strip()):
            return line.strip()
    return "[Your Name]"

def extract_job_info(jd):
    job_title = re.search(r"(Role|Title|Position)[:\-]?\s*(.*)", jd, re.IGNORECASE)
    company = re.search(r"Company[:\-]?\s*(.*)", jd, re.IGNORECASE)
    return (
        job_title.group(2).strip() if job_title else "the position",
        company.group(1).strip() if company else "your company"
    )

def compute_ats_score(resume, jd):
    emb_resume = embedder.encode(clean_text(resume), convert_to_tensor=True)
    emb_jd = embedder.encode(clean_text(jd), convert_to_tensor=True)
    return round(util.pytorch_cos_sim(emb_resume, emb_jd).item() * 100, 2)

def generate_cover_letter(name, title, company):
    return f"""Dear Hiring Manager,

I am interested in the {title} position at {company}. I believe my skills and experience make me a strong candidate. I am excited about the opportunity to contribute and grow with your team.

Thank you for considering my application.

Sincerely,
{name}
"""

# STEP 6: API Endpoint
@app.post("/analyze/")
async def analyze(resume_file: UploadFile, job_desc: str = Form(...), user_name: str = Form("")):
    try:
        with tempfile.NamedTemporaryFile(delete=False) as tmp:
            tmp.write(await resume_file.read())
            tmp_path = tmp.name

        if resume_file.filename.endswith(".pdf"):
            resume_text = extract_text_from_pdf(tmp_path)
        elif resume_file.filename.lower().endswith((".png", ".jpg", ".jpeg")):
            resume_text = extract_text_from_image(tmp_path)
        else:
            return JSONResponse(content={"error": "Unsupported file type"}, status_code=400)

        name = user_name if user_name.strip() else extract_name(resume_text)
        job_title, company = extract_job_info(job_desc)
        ats_score = compute_ats_score(resume_text, job_desc)
        letter = generate_cover_letter(name, job_title, company)

        return {
            "ats_score": f"{ats_score}%",
            "cover_letter": letter
        }
    except Exception as e:
        return JSONResponse(content={"error": str(e)}, status_code=500)

# STEP 7: Start server with ngrok
def start_server():
    try:
        # Show Colab proxy URL
        colab_url = eval_js("google.colab.kernel.proxyPort(8000)")
        print(f"üîó Colab Proxy: {colab_url}")
        print(f"üìò Swagger Docs: {colab_url}/docs")
    except:
        pass

    try:
        token = input("üîê Enter your ngrok authtoken (or press Enter to skip): ").strip()
        if token:
            ngrok.set_auth_token(token)
            public_url = ngrok.connect(8000).public_url
            print(f"üåç Public ngrok URL: {public_url}")
            print(f"üìò Swagger Docs: {public_url}/docs")
    except Exception as e:
        print("‚ö†Ô∏è Ngrok failed:", str(e))

    uvicorn.run(app, host="0.0.0.0", port=8000)

# STEP 8: Launch server in background
print("üöÄ Launching Resume Analyzer API...")
threading.Thread(target=start_server, daemon=True).start()

# Keep notebook alive
while True:
    time.sleep(10)







